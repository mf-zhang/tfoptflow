{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running inference on image pairs\n",
    "============================\n",
    "\n",
    "If you want to use a pre-trained PWC-Net model on your own set of images, you can pass a list of image pairs to a `ModelPWCNet` object using its  `predict_from_img_pairs()` method, as demonstrated here.\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_predict_from_img_pairs.ipynb\n",
    "\n",
    "Run inference on a list of images pairs.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from copy import deepcopy\n",
    "# from skimage.io import imread\n",
    "from cv2 import imread\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_TEST_OPTIONS\n",
    "from visualize import zmf_save_flows_c\n",
    "import rawpy\n",
    "import numpy as np\n",
    "import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set device to use for inference\n",
    "# Here, we're using a GPU (use '/device:CPU:0' to run inference on the CPU)\n",
    "gpu_devices = ['/device:GPU:0']  \n",
    "controller = '/device:GPU:0'\n",
    "\n",
    "# TODO: Set the path to the trained model (make sure you've downloaded it first from http://bit.ly/tfoptflow)\n",
    "# ckpt_path = '../../../data/pretrained_model/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000'\n",
    "\n",
    "# ckpt_path = '../../../workplace/3-noise-model/final/zmf-origChair/pwcnet.ckpt-50000'\n",
    "# ckpt_path = '../../../workplace/3-noise-model/final/zmf-try-my-raw-6-pwcnet-lg-6-2-cyclic/pwcnet.ckpt-50000'\n",
    "# ckpt_path = '../../../workplace/3-noise-model/final/train-on-white-noise/pwcnet.ckpt-50000'\n",
    "# ckpt_path = '../../../workplace/3-noise-model/zmf-finetune/pwcnet.ckpt-48000'\n",
    "\n",
    "# ckpt_path = '../../../workplace/3-noise-model/mix/zmf-allmyppm/pwcnet.ckpt-50000'\n",
    "ckpt_path = '../../../workplace/3-noise-model/mix/zmf-mixwhite/pwcnet.ckpt-50000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.873712089583721\n",
      "8.272701420914863\n",
      "12.545421771236596\n",
      "19.745510215302943\n",
      "33.269437679478166\n",
      "52.38627026105759\n",
      "82.9513810303007\n",
      "148.5211844346308\n",
      "232.21744455597334\n",
      "5.847769296614696\n",
      "8.417754474869234\n",
      "12.768816997407805\n",
      "19.821441508042135\n",
      "33.42236491762654\n",
      "52.9145215472365\n",
      "83.13670222032496\n",
      "149.4791437361091\n",
      "226.40215140787717\n"
     ]
    }
   ],
   "source": [
    "# Build a list of image pairs to process\n",
    "img_pairs = []\n",
    "names = []\n",
    "\n",
    "# PNG\n",
    "# image_path1 = '../../../workplace/1-prove-bad/eva/eva-base/my-simple/6_scale_img1.png'\n",
    "# image_path2 = '../../../workplace/1-prove-bad/eva/eva-base/my-simple/6_scale_img2.png'\n",
    "# image_path1 = '../../../data/dataset/newOptFlow/1/(1).JPG'\n",
    "# image_path2 = '../../../data/dataset/newOptFlow/2/(1).JPG'\n",
    "# image1, image2 = imread(image_path1), imread(image_path2)\n",
    "# img_pairs.append((image1, image2))\n",
    "\n",
    "# ARW\n",
    "canon_im1num = [1,1,2,10,10,11,21,21,21,21,22,22,22,24,25,31,31,31,32,32,33,41,43,51,54] # 25\n",
    "canon_im2num = [2,3,3,11,12,12,22,24,25,26,23,24,27,26,27,32,33,34,33,34,34,42,45,52,55]\n",
    "\n",
    "# sony_im1num = [1,1,1,2,11,11,12,15] # 8\n",
    "# sony_im2num = [2,3,4,4,12,13,13,16]\n",
    "sony_im1num = [1,1] # 8\n",
    "sony_im2num = [2,3]\n",
    "fuji_im1num = [1,1,1,2,2,3,5,6,11,11,11,12,12,12,14,14,15] # 17\n",
    "fuji_im2num = [2,3,4,3,4,4,8,7,12,16,17,13,14,15,16,17,17]\n",
    "\n",
    "def crop(im,h,w,sample_every_n_pixels):\n",
    "    h0 = im.shape[0]\n",
    "    w0 = im.shape[1]\n",
    "    if (h0 < h or w0 < w):\n",
    "        print(\"bad crop\")\n",
    "        return im\n",
    "    newim = im[0:h:sample_every_n_pixels,0:w:sample_every_n_pixels,:]\n",
    "    return newim\n",
    "\n",
    "for i in range(0,2):\n",
    "    foldernum1 = canon_im1num[i]\n",
    "    foldernum2 = canon_im2num[i]\n",
    "    rawnum = len(glob.glob('../../../data/dataset/newOptFlow/canon/%d/*.CR2'%(foldernum1)))\n",
    "    for j in range(rawnum):\n",
    "        image_path1 = '../../../data/dataset/newOptFlow/canon/%d/(%d).CR2'%(foldernum1,j+1)\n",
    "        image_path2 = '../../../data/dataset/newOptFlow/canon/%d/(%d).CR2'%(foldernum2,j+1)\n",
    "#         image_path1 = '../../../data/dataset/newOptFlow/sony/1/(1).ARW'\n",
    "#         image_path2 = '../../../data/dataset/newOptFlow/sony/2/(1).ARW'\n",
    "\n",
    "        raw1 = rawpy.imread(image_path1)\n",
    "        raw2 = rawpy.imread(image_path2)\n",
    "\n",
    "        im1 = raw1.raw_image_visible.astype(np.float32)\n",
    "        im1 = (im1 - 2047) / (16383 - 2047)\n",
    "        ratio = 0.3 / np.mean(im1)\n",
    "        im1 = np.minimum(np.maximum(im1*ratio,0.0),1.0)\n",
    "\n",
    "        im2 = raw2.raw_image_visible.astype(np.float32)\n",
    "        im2 = (im2 - 2047) / (16383 - 2047)\n",
    "        ratio = 0.3 / np.mean(im2)\n",
    "        im2 = np.minimum(np.maximum(im2*ratio,0.0),1.0)\n",
    "        print(ratio)\n",
    "\n",
    "        im1 = np.expand_dims(im1, axis=2)\n",
    "        H = im1.shape[0]\n",
    "        W = im1.shape[1]\n",
    "        image1 = np.concatenate((im1[0:H:2, 0:W:2,:], #r\n",
    "                              (im1[0:H:2, 1:W:2,:]+im1[1:H:2, 0:W:2,:])/2.0, #g\n",
    "                              im1[1:H:2, 1:W:2,:]), axis=2) #b\n",
    "        im2 = np.expand_dims(im2, axis=2)\n",
    "        H = im2.shape[0]\n",
    "        W = im2.shape[1]\n",
    "        image2 = np.concatenate((im2[0:H:2, 0:W:2,:], #r\n",
    "                              (im2[0:H:2, 1:W:2,:]+im2[1:H:2, 0:W:2,:])/2.0, #g\n",
    "                              im2[1:H:2, 1:W:2,:]), axis=2) #b\n",
    "        image1 = crop(image1,1920,2944,2)\n",
    "        image2 = crop(image2,1920,2944,2)\n",
    "        img_pairs.append((image1, image2))\n",
    "        n = '%d-%d_%d'%(foldernum1,foldernum2,j+1)\n",
    "        names.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for inference, starting with the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_TEST_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_path'] = ckpt_path\n",
    "nn_opts['batch_size'] = 1\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# We're running the PWC-Net-large model in quarter-resolution mode\n",
    "# That is, with a 6 level pyramid, and upsampling of level 2 by 4 in each dimension as the final flow prediction\n",
    "nn_opts['use_dense_cx'] = True\n",
    "nn_opts['use_res_cx'] = True\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2\n",
    "\n",
    "# The size of the images in this dataset are not multiples of 64, while the model generates flows padded to multiples\n",
    "# of 64. Hence, we need to crop the predicted flows to their original size\n",
    "nn_opts['adapt_info'] = (1, 436, 1024, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1104 21:33:50.031205 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_base.py:59: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W1104 21:33:50.112115 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_base.py:77: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1104 21:33:50.114075 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_base.py:82: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1104 21:33:51.715600 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_base.py:86: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1104 21:33:51.716507 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_base.py:86: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1104 21:33:51.717042 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_base.py:215: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1104 21:33:51.739511 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_pwcnet.py:1543: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1104 21:33:51.741371 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_pwcnet.py:1086: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n",
      "W1104 21:33:51.762014 139737911805760 deprecation.py:323] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_pwcnet.py:1094: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1104 21:33:52.503699 139737911805760 deprecation.py:506] From /home/zhangmf/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1104 21:33:52.748478 139737911805760 deprecation.py:323] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_pwcnet.py:1221: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "W1104 21:33:55.309040 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_pwcnet.py:1590: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "W1104 21:33:55.311277 139737911805760 deprecation_wrapper.py:119] From /home/zhangmf/Documents/Github/tfoptflow/tfoptflow/model_base.py:119: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1104 21:33:55.437364 139737911805760 deprecation.py:323] From /home/zhangmf/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I1104 21:33:55.443594 139737911805760 saver.py:1280] Restoring parameters from ../../../workplace/3-noise-model/mix/zmf-mixwhite/pwcnet.ckpt-50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... model built.\n",
      "Loading model checkpoint ../../../workplace/3-noise-model/mix/zmf-mixwhite/pwcnet.ckpt-50000 for eval or testing...\n",
      "\n",
      "... model loaded\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model in inference mode and display the model configuration\n",
    "nn = ModelPWCNet(mode='test', options=nn_opts)\n",
    "# nn.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions and display them\n",
    "pred_labels = nn.predict_from_img_pairs(img_pairs, batch_size=1, verbose=False)\n",
    "zmf_save_flows_c(names, img_pairs, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
